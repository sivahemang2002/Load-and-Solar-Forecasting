# -*- coding: utf-8 -*-
"""Load Forecasting for Enegry Consumption.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_ukxDJxckbl0v42SsrhpFiR5HtD-kaJV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

URL = 'https://raw.githubusercontent.com/MohamadNach/Machine-Learning-to-Predict-Energy-Consumption/master/events.csv'
df = pd.read_csv(URL)

df.head()

del df["Start time UTC"]
del df["End time UTC"]
del df["Start time UTC+03:00"]
df.rename(columns={"End time UTC+03:00":"DateTime","Electricity consumption in Finland":"Consumption"},inplace=True)
print(df.head(5))

df['DateTime'] = pd.to_datetime(df['DateTime'])

df = df.set_index('DateTime')

df_resampled = df.resample('30T').mean()

df_resampled = df_resampled.interpolate(method='linear')

df_resampled = df_resampled.rename(columns={'electricity_consumption': 'electricity_consumption_30min'})

df_resampled = df_resampled.reset_index()

df_resampled.head()

df_resampled = df_resampled.set_index('DateTime')

df_resampled1 = df_resampled.resample('15T').mean()

df_resampled1 = df_resampled1.interpolate(method='linear')

df_resampled1 = df_resampled1.reset_index()

df_resampled1.head()

dataset = df_resampled1
dataset["Month"] = pd.to_datetime(df_resampled1["DateTime"]).dt.month
dataset["Year"] = pd.to_datetime(df_resampled1["DateTime"]).dt.year
dataset["Date"] = pd.to_datetime(df_resampled1["DateTime"]).dt.date
dataset["Time"] = pd.to_datetime(df_resampled1["DateTime"]).dt.time
dataset["Week"] = pd.to_datetime(df_resampled1["DateTime"]).dt.isocalendar().week
dataset["Day"] = pd.to_datetime(df_resampled1["DateTime"]).dt.day_name()

dataset.head()

dataset = df_resampled1.set_index("DateTime")
dataset.index = pd.to_datetime(dataset.index)

newDataSet = dataset

print("Old Dataset: ", df.shape)
print("New Dataset: ", newDataSet.shape)

newDataSet.head()

newDataSet.tail()

y = newDataSet["Consumption"]
print(y[0])
y.shape

# Normalize data before model fitting
# it will boost the performance( in neural networks) + transform
from sklearn.preprocessing import MinMaxScaler
# scale of the output and input inthe range 0-1 to match the scale of the layer of LSTM
scaler = MinMaxScaler(feature_range = (0,1)) 
# reshape: convert the univariate 1D array into 2D
y = scaler.fit_transform(np.array(y).reshape(-1,1))
print("Normalizing data before model fitting")
print(y[:10])
# y.shape



training_size = int(len(y)*0.80)
test_size = len(y)- training_size
val_size = int(training_size*0.20)
train_data , test_data , val_data = y[0:training_size-val_size,:] , y[training_size:len(y),:1], y[len(y)-test_size-val_size:len(y)-test_size,:1]
# print(training_size)
# print(test_size)
# print(val_size)
# print(train_data.shape)
# print(test_data.shape)
# print(val_data.shape)

def create_dataset(dataset, time_step = 1):
  dataX, dataY = [] , []
  for i in range(len(dataset)-time_step-1):
    a = dataset[i:(i+time_step),0]
    dataX.append(a)
    dataY.append(dataset[i + time_step,0])
  return np.array(dataX), np.array(dataY)

time_step = 96
X_train, y_train = create_dataset(train_data, time_step)
X_test, ytest = create_dataset(test_data, time_step)
X_val, yval = create_dataset(val_data, time_step)
# print(X_train.shape) # the 100 is time_step
# print(y_train.shape)
# print(X_test.shape)
# print(ytest.shape)
# print(X_val.shape)
# print(yval.shape)

X_train = X_train.reshape(X_train.shape[0],X_train.shape[1], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1],1)
X_val = X_val.reshape(X_val.shape[0], X_val.shape[1],1)

print("X_train shape: ", X_train.shape)
print("X_test shape: ",X_test.shape)
print("X_val shape: ",X_val.shape)

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout

model = Sequential()

# Adding the first LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50, return_sequences = True, input_shape = (time_step, 1)))
model.add(Dropout(0.2))

# Adding a second LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50, return_sequences = True))
# model.add(Dropout(0.2))

# # Adding a third LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50, return_sequences = True))
# model.add(Dropout(0.2))

# Adding a fourth LSTM layer and some Dropout regularisation
model.add(LSTM(units = 50))
# model.add(Dropout(0.2))

# Adding the output layer
model.add(Dense(units = 1))

# Compiling the RNN
model.compile(optimizer = 'adam', loss = 'mean_squared_error')

history = model.fit(X_train, y_train, validation_data = (X_val,yval), verbose = 1,epochs = 20 ,batch_size = 20)

plt.figure(figsize=(10,10))
plt.plot(history.history['loss']) # tb
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

train_predict=model.predict(X_train)
test_predict=model.predict(X_test)
val_predict=model.predict(X_val)

from sklearn.metrics import mean_squared_error, r2_score
import math

# Transform back to original form
train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)
val_predict = scaler.inverse_transform(val_predict)

# Calculate root mean squared error for train, test, and validation sets
train_rmse = math.sqrt(mean_squared_error(y_train, train_predict))
test_rmse = math.sqrt(mean_squared_error(ytest, test_predict))
val_rmse = math.sqrt(mean_squared_error(yval, val_predict))

# Calculate R2 score for train, test, and validation sets
train_r2 = r2_score(y_train, train_predict)
test_r2 = r2_score(ytest, test_predict)
val_r2 = r2_score(yval, val_predict)

print('Train RMSE:', train_rmse)
print('Test RMSE:', test_rmse)
print('Validation RMSE:', val_rmse)
print('Train R2:', train_r2)
print('Test R2:', test_r2)
print('Validation R2:', val_r2)

train_predictions = model.predict(X_train)
train_predictions =scaler.inverse_transform(train_predictions)

y_train = y_train.reshape(y_train.shape[0], 1)
actual = scaler.inverse_transform(y_train)
train_results = pd.DataFrame()



train_results

type(actual)

train_predictions

plt.figure(figsize=(20,10))

# Actual Consumption



plt.plot(actual[-96:])
plt.plot(train_predictions[-96:])

plt.legend(['actual','train_predictions'])
plt.xlabel('Time Steps')
plt.ylabel('Consumption MWh')
plt.show()

# Predicting consumption using test data
test_predictions = model.predict(X_test)
test_predictions =scaler.inverse_transform(test_predictions)

ytest = ytest.reshape(ytest.shape[0], 1)
actual_test = scaler.inverse_transform(ytest)

test_results = pd.DataFrame()
test_results["test Predictions"] = test_predictions.tolist()
test_results["Actuals_test"] = actual_test.tolist()

test_results

plt.figure(figsize=(20,10))

# Actual Consumption



plt.plot(actual[-960:])
plt.plot(train_predictions[-960:])

plt.legend(['actual','test_predictions'])
plt.xlabel('Time Steps')
plt.ylabel('Consumption MWh')
plt.show()

x_input=test_data[-96:].reshape(1,-1)
print(x_input.shape)

temp_input=list(x_input)
temp_input=temp_input[0].tolist()

from numpy import array

lst_output=[]
n_steps=96
i=0
test = ""
while(i<96):
    
    if(len(temp_input)>96):
        test = "if"
        #print(temp_input)
        x_input=np.array(temp_input[1:])
        print("{} hour input {}".format(i,x_input))
        x_input=x_input.reshape(1,-1)
        x_input = x_input.reshape((1, n_steps, 1))
        #print(x_input)
        yhat = model.predict(x_input, verbose=0)
        print("{} hour output {}".format(i,yhat))
        temp_input.extend(yhat[0].tolist())
        temp_input=temp_input[1:]
        #print(temp_input)
        lst_output.extend(yhat.tolist())
        i=i+1
    else:
        test="else"
        x_input = x_input.reshape((1, n_steps,1))
        yhat = model.predict(x_input, verbose=0)
        #print(yhat[0])
        temp_input.extend(yhat[0].tolist())
        #print(len(temp_input))
        lst_output.extend(yhat.tolist())
        i=i+1

    
print(test)
print(len(lst_output))

print(len(y))
day_new=np.arange(1,96)
day_pred=np.arange(96, 192)
plt.figure(figsize = (15,10))
plt.plot(day_new,scaler.inverse_transform(y[-95:]))
plt.plot(day_pred,scaler.inverse_transform(lst_output))
print(scaler.inverse_transform(lst_output))
output = scaler.inverse_transform(lst_output)

output

type(output)

df = pd.DataFrame(output)

df.to_csv("load_forecasting_next-day.csv")

model.save('LSTM_load_forecast.h5')

